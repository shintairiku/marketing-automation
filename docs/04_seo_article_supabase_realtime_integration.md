# SEOè¨˜äº‹ç”Ÿæˆã«ãŠã‘ã‚‹Supabase Realtimeé€£æºä»•æ§˜

## æ¦‚è¦

ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§ã¯ã€SEOè¨˜äº‹ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ã§å¾“æ¥ã®WebSocketé€šä¿¡ã«ä»£ã‚ã‚Šå°å…¥ã•ã‚ŒãŸSupabase Realtimeã«ã‚ˆã‚‹éåŒæœŸé€šä¿¡ã®ä»•æ§˜ã«ã¤ã„ã¦è©³ç´°ã«è§£èª¬ã—ã¾ã™ã€‚Supabase Realtimeã¯ã€PostgreSQLã®å¤‰æ›´ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é…ä¿¡ã™ã‚‹ä»•çµ„ã¿ã‚’æä¾›ã—ã€ã‚ˆã‚Šä¿¡é ¼æ€§ãŒé«˜ãæ‹¡å¼µæ€§ã®ã‚ã‚‹ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€šä¿¡ã‚’å®Ÿç¾ã—ã¦ã„ã¾ã™ã€‚

## æŠ€è¡“èƒŒæ™¯

### WebSocket ã‹ã‚‰Supabase Realtime ã¸ã®ç§»è¡Œç†ç”±

1. **æ¥ç¶šã®å®‰å®šæ€§**: WebSocketã®æ¥ç¶šæ–­ãƒ»å†æ¥ç¶šã®è¤‡é›‘ã•ã‚’è§£æ¶ˆ
2. **ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£**: Supabaseã®ã‚¤ãƒ³ãƒ•ãƒ©ã‚’æ´»ç”¨ã—ãŸè‡ªå‹•ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
3. **ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§**: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å¤‰æ›´ã¨ã®å®Œå…¨ãªåŒæœŸä¿è¨¼
4. **é–‹ç™ºåŠ¹ç‡**: WebSocketã‚µãƒ¼ãƒãƒ¼ã®ç®¡ç†ãŒä¸è¦
5. **éšœå®³å¾©æ—§**: è‡ªå‹•çš„ãªæ¥ç¶šå¾©æ—§ã¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é…ä¿¡ä¿è¨¼

### ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¦‚è¦

```mermaid
graph TD
    A[Backend FastAPI] --> B[Supabase PostgreSQL]
    B --> C[Supabase Realtime Engine]
    C --> D[Frontend Client]
    
    subgraph "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«"
        E[generated_articles_state]
        F[process_events]
    end
    
    subgraph "Realtime Channels"
        G[process_events:process_id=eq.XXX]
        H[process_state:XXX]
    end
    
    B --> E
    B --> F
    E --> G
    F --> H
```

## ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ 

### 1. process_events ãƒ†ãƒ¼ãƒ–ãƒ«

ãƒ—ãƒ­ã‚»ã‚¹ã®å„ã‚¤ãƒ™ãƒ³ãƒˆã‚’æ™‚ç³»åˆ—ã§è¨˜éŒ²ã—ã€ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã«ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é…ä¿¡ã—ã¾ã™ã€‚

```sql
CREATE TABLE process_events (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  process_id UUID NOT NULL REFERENCES generated_articles_state(id) ON DELETE CASCADE,
  
  -- Event details
  event_type TEXT NOT NULL,
  event_data JSONB NOT NULL DEFAULT '{}'::jsonb,
  event_sequence INTEGER NOT NULL,
  
  -- Event metadata
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  published_at TIMESTAMP WITH TIME ZONE,
  acknowledged_by TEXT[] DEFAULT '{}', -- User IDs who acknowledged this event
  delivery_attempts INTEGER DEFAULT 0,
  
  -- Event categorization
  event_category TEXT DEFAULT 'system',
  event_priority INTEGER DEFAULT 5,
  event_source TEXT DEFAULT 'backend',
  
  -- Retention and cleanup
  expires_at TIMESTAMP WITH TIME ZONE,
  archived BOOLEAN DEFAULT FALSE,
  
  -- Ensure unique sequence per process
  CONSTRAINT unique_process_sequence UNIQUE(process_id, event_sequence)
);
```

#### ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹æˆ

```sql
-- åŠ¹ç‡çš„ãªã‚¯ã‚¨ãƒªã®ãŸã‚ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
CREATE INDEX idx_process_events_process_id ON process_events(process_id);
CREATE INDEX idx_process_events_created_at ON process_events(created_at DESC);
CREATE INDEX idx_process_events_type ON process_events(event_type);
CREATE INDEX idx_process_events_category ON process_events(event_category);
CREATE INDEX idx_process_events_published ON process_events(published_at DESC) 
  WHERE published_at IS NOT NULL;
CREATE INDEX idx_process_events_undelivered ON process_events(process_id, event_sequence) 
  WHERE delivery_attempts < 3 AND acknowledged_by = '{}';
```

### 2. generated_articles_state ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆæ‹¡å¼µãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼‰

æ—¢å­˜ãƒ†ãƒ¼ãƒ–ãƒ«ã«Realtimeå¯¾å¿œã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è¿½åŠ ã—ã¦ã„ã¾ã™ã€‚

```sql
-- Realtimeå¯¾å¿œãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®è¿½åŠ 
ALTER TABLE generated_articles_state 
ADD COLUMN realtime_channel TEXT,
ADD COLUMN last_realtime_event JSONB,
ADD COLUMN realtime_subscriptions JSONB DEFAULT '[]'::jsonb,
ADD COLUMN executing_step TEXT,
ADD COLUMN step_execution_start TIMESTAMP WITH TIME ZONE,
ADD COLUMN step_execution_metadata JSONB DEFAULT '{}'::jsonb,
ADD COLUMN background_task_id TEXT,
ADD COLUMN task_priority INTEGER DEFAULT 5,
ADD COLUMN retry_count INTEGER DEFAULT 0,
ADD COLUMN max_retries INTEGER DEFAULT 3,
ADD COLUMN user_input_timeout TIMESTAMP WITH TIME ZONE,
ADD COLUMN input_reminder_sent BOOLEAN DEFAULT FALSE,
ADD COLUMN interaction_history JSONB DEFAULT '[]'::jsonb,
ADD COLUMN process_type TEXT DEFAULT 'article_generation',
ADD COLUMN parent_process_id UUID REFERENCES generated_articles_state(id),
ADD COLUMN process_tags TEXT[] DEFAULT '{}',
ADD COLUMN step_durations JSONB DEFAULT '{}'::jsonb,
ADD COLUMN total_processing_time INTERVAL,
ADD COLUMN estimated_completion_time TIMESTAMP WITH TIME ZONE;
```

## ã‚¤ãƒ™ãƒ³ãƒˆé…ä¿¡ä»•æ§˜

### ã‚¤ãƒ™ãƒ³ãƒˆç¨®é¡ä¸€è¦§

| ã‚¤ãƒ™ãƒ³ãƒˆç¨®é¡ | èª¬æ˜ | é€ä¿¡ã‚¿ã‚¤ãƒŸãƒ³ã‚° | ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ä¾‹ |
|-------------|------|---------------|-------------|
| `process_created` | ãƒ—ãƒ­ã‚»ã‚¹é–‹å§‹ | ãƒ—ãƒ­ã‚»ã‚¹åˆæœŸåŒ–å®Œäº†æ™‚ | `{"process_id": "...", "initial_request": {...}}` |
| `step_update` | ã‚¹ãƒ†ãƒƒãƒ—æ›´æ–° | å„ã‚¹ãƒ†ãƒƒãƒ—é–‹å§‹æ™‚ | `{"step": "keyword_analyzing", "message": "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æä¸­..."}` |
| `step_completed` | ã‚¹ãƒ†ãƒƒãƒ—å®Œäº† | å„ã‚¹ãƒ†ãƒƒãƒ—å®Œäº†æ™‚ | `{"step": "persona_generating", "result": {...}}` |
| `user_input_required` | ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›å¾…ã¡ | å…¥åŠ›å¾…æ©Ÿé–‹å§‹æ™‚ | `{"input_type": "SELECT_THEME", "options": [...]}` |
| `user_input_received` | ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›å—ä¿¡ | å…¥åŠ›å‡¦ç†å®Œäº†æ™‚ | `{"input_type": "SELECT_THEME", "selected": {...}}` |
| `research_progress` | ãƒªã‚µãƒ¼ãƒé€²æ— | å„æ¤œç´¢ã‚¯ã‚¨ãƒªå®Ÿè¡Œæ™‚ | `{"query_index": 1, "total_queries": 3, "query": "..."}` |
| `section_chunk` | ã‚»ã‚¯ã‚·ãƒ§ãƒ³åŸ·ç­†é€²æ— | ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡ºåŠ›æ™‚ | `{"section_index": 0, "chunk": "...", "is_complete": false}` |
| `section_completed` | ã‚»ã‚¯ã‚·ãƒ§ãƒ³å®Œäº† | ã‚»ã‚¯ã‚·ãƒ§ãƒ³åŸ·ç­†å®Œäº†æ™‚ | `{"section_index": 0, "content": "...", "images": [...]}` |
| `image_placeholder_generated` | ç”»åƒãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ç”Ÿæˆ | ç”»åƒæŒ‡ç¤ºç”Ÿæˆæ™‚ | `{"placeholder_id": "...", "description": "...", "prompt": "..."}` |
| `image_generated` | ç”»åƒç”Ÿæˆå®Œäº† | ç”»åƒç”Ÿæˆãƒ»ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†æ™‚ | `{"placeholder_id": "...", "image_url": "...", "gcs_path": "..."}` |
| `process_paused` | ãƒ—ãƒ­ã‚»ã‚¹ä¸€æ™‚åœæ­¢ | ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¸€æ™‚åœæ­¢è¦æ±‚æ™‚ | `{"reason": "user_request", "resume_available": true}` |
| `process_resumed` | ãƒ—ãƒ­ã‚»ã‚¹å†é–‹ | ä¸€æ™‚åœæ­¢ã‹ã‚‰ã®å¾©æ—§æ™‚ | `{"resumed_from_step": "outline_generating"}` |
| `process_completed` | ãƒ—ãƒ­ã‚»ã‚¹å®Œäº† | è¨˜äº‹ç”Ÿæˆå®Œäº†æ™‚ | `{"article_id": "...", "final_content": "...", "statistics": {...}}` |
| `process_error` | ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ | ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ | `{"error_type": "recoverable", "step": "...", "message": "...", "recovery_options": [...]}` |
| `heartbeat` | ç”Ÿå­˜ç¢ºèª | å®šæœŸçš„ï¼ˆ30ç§’é–“éš”ï¼‰ | `{"timestamp": "...", "active_connections": 1}` |

### ã‚¤ãƒ™ãƒ³ãƒˆãƒšã‚¤ãƒ­ãƒ¼ãƒ‰æ§‹é€ 

#### åŸºæœ¬ã‚¤ãƒ™ãƒ³ãƒˆæ§‹é€ 
```json
{
  "id": "event-uuid",
  "process_id": "process-uuid",
  "event_type": "step_update",
  "event_sequence": 15,
  "event_category": "system",
  "event_priority": 5,
  "event_source": "backend",
  "created_at": "2025-01-31T12:00:00Z",
  "event_data": {
    // ã‚¤ãƒ™ãƒ³ãƒˆå›ºæœ‰ã®ãƒ‡ãƒ¼ã‚¿
  }
}
```

#### å…·ä½“çš„ãªã‚¤ãƒ™ãƒ³ãƒˆä¾‹

**step_update ã‚¤ãƒ™ãƒ³ãƒˆ**
```json
{
  "id": "550e8400-e29b-41d4-a716-446655440000",
  "process_id": "123e4567-e89b-12d3-a456-426614174000",
  "event_type": "step_update",
  "event_sequence": 5,
  "event_category": "process",
  "event_priority": 3,
  "event_source": "generation_flow_manager",
  "created_at": "2025-01-31T12:00:15Z",
  "event_data": {
    "step": "theme_generating",
    "previous_step": "persona_selected",
    "message": "ãƒ†ãƒ¼ãƒæ¡ˆã‚’ç”Ÿæˆä¸­...",
    "progress": {
      "completed_steps": 3,
      "total_steps": 8,
      "percentage": 37.5
    },
    "estimated_completion": "2025-01-31T12:02:30Z",
    "image_mode": false
  }
}
```

**user_input_required ã‚¤ãƒ™ãƒ³ãƒˆ**
```json
{
  "id": "550e8400-e29b-41d4-a716-446655440001",
  "process_id": "123e4567-e89b-12d3-a456-426614174000",
  "event_type": "user_input_required",
  "event_sequence": 8,
  "event_category": "interaction",
  "event_priority": 1,
  "event_source": "user_interaction_manager",
  "created_at": "2025-01-31T12:01:45Z",
  "event_data": {
    "input_type": "SELECT_THEME",
    "timeout": "2025-01-31T12:31:45Z",
    "options": [
      {
        "index": 0,
        "title": "æœ­å¹Œã§å­è‚²ã¦ä¸–ä»£ãŒé¸ã¶ã¹ãè‡ªç„¶ç´ ææ³¨æ–‡ä½å®…ã®å®Œå…¨ã‚¬ã‚¤ãƒ‰",
        "description": "æœ­å¹Œã®å³ã—ã„å†¬ã§ã‚‚å¿«é©ã«éã”ã›ã‚‹è‡ªç„¶ç´ æä½å®…ã®ç‰¹å¾´ã€é¸ã³æ–¹ã€åœ°åŸŸã«é©ã—ãŸè¨­è¨ˆã®ãƒã‚¤ãƒ³ãƒˆã‚’ã€å­è‚²ã¦ä¸–ä»£ã®è¦–ç‚¹ã‹ã‚‰å¾¹åº•è§£èª¬ã€‚",
        "keywords": ["æœ­å¹Œ", "æ³¨æ–‡ä½å®…", "è‡ªç„¶ç´ æ", "å­è‚²ã¦", "æ–­ç†±æ€§èƒ½", "å¥åº·ä½å®…"]
      },
      {
        "index": 1,
        "title": "è‡ªç„¶ç´ æã§å»ºã¦ã‚‹æœ­å¹Œã®æ³¨æ–‡ä½å®…ï¼šå­ä¾›ã®å¥åº·ã‚’å®ˆã‚‹å®¶ã¥ãã‚Šã®ã™ã¹ã¦",
        "description": "åŒ–å­¦ç‰©è³ªã‚’é¿ã‘ã€å­ä¾›ã®å¥åº·ã‚’æœ€å„ªå…ˆã«ã—ãŸè‡ªç„¶ç´ æä½å®…ã®å»ºç¯‰äº‹ä¾‹ã¨ã€æœ­å¹Œã‚¨ãƒªã‚¢ã§ã®å®Ÿè·µçš„ãªå®¶ã¥ãã‚Šãƒã‚¦ãƒã‚¦ã‚’ç´¹ä»‹ã€‚",
        "keywords": ["è‡ªç„¶ç´ æ", "å¥åº·ä½å®…", "å­ä¾›", "æœ­å¹Œ", "æ³¨æ–‡ä½å®…", "ç„¡æ·»åŠ "]
      }
    ],
    "additional_actions": ["regenerate", "edit", "skip"]
  }
}
```

**section_chunk ã‚¤ãƒ™ãƒ³ãƒˆï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰**
```json
{
  "id": "550e8400-e29b-41d4-a716-446655440002",
  "process_id": "123e4567-e89b-12d3-a456-426614174000",
  "event_type": "section_chunk",
  "event_sequence": 25,
  "event_category": "generation",
  "event_priority": 4,
  "event_source": "section_writer_agent",
  "created_at": "2025-01-31T12:05:12Z",
  "event_data": {
    "section_index": 2,
    "section_heading": "æœ­å¹Œã®å†¬ã‚’å¿«é©ã«éã”ã™è‡ªç„¶ç´ æä½å®…ã®è¨­è¨ˆãƒã‚¤ãƒ³ãƒˆ",
    "html_chunk": "<p>æœ­å¹Œã®å³ã—ã„å†¬å­£ã«ãŠã„ã¦ã¯ã€è‡ªç„¶ç´ æã‚’ä½¿ç”¨ã—ãŸä½å®…ã§ã‚‚é«˜ã„æ–­ç†±æ€§èƒ½ãŒä¸å¯æ¬ ã§ã™ã€‚</p>",
    "is_complete": false,
    "total_chars_generated": 145,
    "estimated_section_length": 800,
    "generation_progress": 18.1,
    "image_mode": false
  }
}
```

## ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰å®Ÿè£…ä»•æ§˜

### ã‚¤ãƒ™ãƒ³ãƒˆé€ä¿¡ãƒ¡ã‚«ãƒ‹ã‚ºãƒ 

#### ProcessEventPublisher ã‚¯ãƒ©ã‚¹
```python
class ProcessEventPublisher:
    """ãƒ—ãƒ­ã‚»ã‚¹ã‚¤ãƒ™ãƒ³ãƒˆã®é…ä¿¡ã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, supabase_client: Client):
        self.supabase = supabase_client
        self.event_sequence_counters: Dict[str, int] = {}
    
    async def publish_event(
        self, 
        process_id: str, 
        event_type: str, 
        event_data: Dict[str, Any],
        event_category: str = "system",
        event_priority: int = 5
    ) -> str:
        """ã‚¤ãƒ™ãƒ³ãƒˆã‚’process_eventsãƒ†ãƒ¼ãƒ–ãƒ«ã«æŒ¿å…¥ã—ã¦Realtimeé…ä¿¡"""
        
        # ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ç•ªå·ã‚’ç”Ÿæˆ
        sequence = self._get_next_sequence(process_id)
        
        # ã‚¤ãƒ™ãƒ³ãƒˆãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’ä½œæˆ
        event_record = {
            "process_id": process_id,
            "event_type": event_type,
            "event_data": event_data,
            "event_sequence": sequence,
            "event_category": event_category,
            "event_priority": event_priority,
            "event_source": "backend",
            "published_at": datetime.now(timezone.utc).isoformat()
        }
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æŒ¿å…¥ï¼ˆè‡ªå‹•çš„ã«Realtimeé…ä¿¡ã•ã‚Œã‚‹ï¼‰
        result = self.supabase.table("process_events").insert(event_record).execute()
        
        if result.data:
            event_id = result.data[0]["id"]
            logger.info(f"Event published: {event_type} for process {process_id} (sequence: {sequence})")
            return event_id
        else:
            logger.error(f"Failed to publish event: {event_type} for process {process_id}")
            raise Exception("Failed to publish event")
    
    def _get_next_sequence(self, process_id: str) -> int:
        """ãƒ—ãƒ­ã‚»ã‚¹ã”ã¨ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ç•ªå·ã‚’ç®¡ç†"""
        if process_id not in self.event_sequence_counters:
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰æœ€æ–°ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ç•ªå·ã‚’å–å¾—
            result = self.supabase.table("process_events")\
                .select("event_sequence")\
                .eq("process_id", process_id)\
                .order("event_sequence", desc=True)\
                .limit(1)\
                .execute()
            
            last_sequence = result.data[0]["event_sequence"] if result.data else 0
            self.event_sequence_counters[process_id] = last_sequence
        
        self.event_sequence_counters[process_id] += 1
        return self.event_sequence_counters[process_id]
```

#### GenerationUtilså†…ã®å®Ÿè£…

```python
class GenerationUtils:
    async def send_server_event(self, context: ArticleContext, payload: Any):
        """Supabase Realtimeã‚¤ãƒ™ãƒ³ãƒˆé€ä¿¡ï¼ˆæ—§WebSocketé€ä¿¡ã‹ã‚‰ç§»è¡Œï¼‰"""
        
        if not context.process_id:
            logger.warning("Process ID not found, skipping event publication")
            return
        
        # ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã‚’JSONå½¢å¼ã«å¤‰æ›
        if hasattr(payload, 'model_dump'):
            event_data = payload.model_dump()
        elif hasattr(payload, 'dict'):
            event_data = payload.dict()
        else:
            event_data = dict(payload) if payload else {}
        
        # ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ã‚’æ±ºå®š
        event_type = self._determine_event_type(payload)
        
        # RealtimeçµŒç”±ã§é…ä¿¡
        await self.event_publisher.publish_event(
            process_id=context.process_id,
            event_type=event_type,
            event_data=event_data,
            event_category="generation"
        )
    
    def _determine_event_type(self, payload: Any) -> str:
        """ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã®å‹ã‹ã‚‰ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ã‚’æ±ºå®š"""
        payload_type = type(payload).__name__
        
        type_mapping = {
            "StatusUpdatePayload": "step_update",
            "ThemeProposalPayload": "user_input_required",
            "ResearchProgressPayload": "research_progress",
            "SectionChunkPayload": "section_chunk",
            "FinalResultPayload": "process_completed",
            "ErrorPayload": "process_error"
        }
        
        return type_mapping.get(payload_type, "generic_event")
```

### ãƒ—ãƒ­ã‚»ã‚¹çŠ¶æ…‹åŒæœŸ

#### ProcessPersistenceService ã®æ‹¡å¼µ
```python
async def save_context_to_db(
    self, 
    context: ArticleContext, 
    process_id: str = None, 
    user_id: str = None
):
    """ArticleContextã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ï¼ˆRealtimeå¯¾å¿œï¼‰"""
    
    if not process_id:
        process_id = context.process_id
    
    # åŸºæœ¬çš„ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä¿å­˜
    update_data = {
        "article_context": context.model_dump(exclude={"websocket", "user_response_event"}),
        "status": self._determine_status_from_step(context.current_step),
        "current_step": context.current_step,
        "updated_at": datetime.now(timezone.utc).isoformat(),
        "realtime_channel": f"process_{process_id}",
        "executing_step": context.executing_step,
        "step_execution_metadata": {
            "step_start_time": getattr(context, 'step_execution_start', None),
            "expected_user_input": context.expected_user_input,
            "is_waiting_for_input": bool(context.expected_user_input)
        }
    }
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ›´æ–°ï¼ˆè‡ªå‹•çš„ã«Realtimeé…ä¿¡ã•ã‚Œã‚‹ï¼‰
    result = self.supabase.table("generated_articles_state")\
        .update(update_data)\
        .eq("id", process_id)\
        .execute()
    
    if result.data:
        logger.info(f"Context saved for process {process_id}, step: {context.current_step}")
        
        # çŠ¶æ…‹å¤‰æ›´ã‚¤ãƒ™ãƒ³ãƒˆã‚’æ˜ç¤ºçš„ã«é€ä¿¡
        await self.event_publisher.publish_event(
            process_id=process_id,
            event_type="state_updated",
            event_data={
                "current_step": context.current_step,
                "status": update_data["status"],
                "is_waiting_for_input": update_data["step_execution_metadata"]["is_waiting_for_input"]
            },
            event_category="state"
        )
    else:
        logger.error(f"Failed to save context for process {process_id}")
        raise Exception("Failed to save context")
```

## ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰å®Ÿè£…ä»•æ§˜

### Supabase Realtime è³¼èª­

#### useSupabaseRealtime ãƒ•ãƒƒã‚¯
```typescript
import { useEffect, useState, useCallback } from 'react';
import { supabase } from '@/libs/supabase/supabase-client';
import { RealtimeChannel, REALTIME_LISTEN_TYPES } from '@supabase/supabase-js';

export interface ProcessEvent {
  id: string;
  process_id: string;
  event_type: string;
  event_data: any;
  event_sequence: number;
  created_at: string;
  event_category: string;
  event_priority: number;
}

export interface ProcessState {
  id: string;
  current_step: string;
  status: string;
  article_context: any;
  updated_at: string;
  is_waiting_for_input?: boolean;
  expected_user_input?: string;
}

export const useSupabaseRealtime = ({ 
  processId, 
  userId,
  onProcessEvent,
  onProcessStateUpdate,
  autoConnect = true 
}: {
  processId?: string;
  userId?: string;
  onProcessEvent?: (event: ProcessEvent) => void;
  onProcessStateUpdate?: (state: ProcessState) => void;
  autoConnect?: boolean;
}) => {
  const [isConnected, setIsConnected] = useState(false);
  const [isConnecting, setIsConnecting] = useState(false);
  const [connectionError, setConnectionError] = useState<string | null>(null);
  const [channel, setChannel] = useState<RealtimeChannel | null>(null);
  const [stateChannel, setStateChannel] = useState<RealtimeChannel | null>(null);

  const connect = useCallback(async () => {
    if (!processId || isConnecting || isConnected) return;

    try {
      setIsConnecting(true);
      setConnectionError(null);

      // Process events channel
      const eventsChannel = supabase
        .channel(`process_events:process_id=eq.${processId}`)
        .on(
          'postgres_changes' as REALTIME_LISTEN_TYPES,
          {
            event: 'INSERT',
            schema: 'public',
            table: 'process_events',
            filter: `process_id=eq.${processId}`,
          },
          (payload) => {
            const event = payload.new as ProcessEvent;
            console.log('ğŸ“¨ Process event received:', event.event_type, event);
            onProcessEvent?.(event);
          }
        )
        .on('system', (status) => {
          console.log('ğŸ“¡ Events channel status:', status);
          if (status === 'SUBSCRIBED') {
            setIsConnected(true);
            setIsConnecting(false);
          }
        });

      // Process state channel
      const processStateChannel = supabase
        .channel(`process_state:${processId}`)
        .on(
          'postgres_changes' as REALTIME_LISTEN_TYPES,
          {
            event: 'UPDATE',
            schema: 'public',
            table: 'generated_articles_state',
            filter: `id=eq.${processId}`,
          },
          (payload) => {
            const state = payload.new as ProcessState;
            console.log('ğŸ”„ Process state updated:', state.current_step, state);
            onProcessStateUpdate?.(state);
          }
        );

      // Subscribe to channels
      await eventsChannel.subscribe();
      await processStateChannel.subscribe();

      setChannel(eventsChannel);
      setStateChannel(processStateChannel);

    } catch (error) {
      console.error('âŒ Failed to connect to Realtime:', error);
      setConnectionError(error instanceof Error ? error.message : 'Connection failed');
      setIsConnecting(false);
    }
  }, [processId, isConnecting, isConnected, onProcessEvent, onProcessStateUpdate]);

  const disconnect = useCallback(() => {
    if (channel) {
      supabase.removeChannel(channel);
      setChannel(null);
    }
    if (stateChannel) {
      supabase.removeChannel(stateChannel);
      setStateChannel(null);
    }
    setIsConnected(false);
    setIsConnecting(false);
  }, [channel, stateChannel]);

  useEffect(() => {
    if (autoConnect && processId) {
      connect();
    }

    return () => {
      disconnect();
    };
  }, [autoConnect, processId, connect, disconnect]);

  return {
    isConnected,
    isConnecting,
    connectionError,
    connect,
    disconnect,
    channel,
    stateChannel
  };
};
```

#### useArticleGenerationRealtime ãƒ•ãƒƒã‚¯ï¼ˆçµ±åˆç‰ˆï¼‰
```typescript
export const useArticleGenerationRealtime = ({ 
  processId, 
  userId,
  autoConnect = true 
}: UseArticleGenerationRealtimeOptions) => {
  const [state, setState] = useState<GenerationState>(initialState);
  const [connectionState, setConnectionState] = useState({
    isConnected: false,
    isConnecting: false,
    error: null
  });

  // Process event handler
  const handleProcessEvent = useCallback((event: ProcessEvent) => {
    console.log(`ğŸ¯ Processing event: ${event.event_type}`, event);
    
    switch (event.event_type) {
      case 'step_update':
        setState(prev => ({
          ...prev,
          currentStep: event.event_data.step,
          steps: updateStepStatus(prev.steps, event.event_data.step, 'in_progress')
        }));
        break;

      case 'user_input_required':
        setState(prev => ({
          ...prev,
          isWaitingForInput: true,
          inputType: event.event_data.input_type,
          [getStateFieldForInputType(event.event_data.input_type)]: event.event_data.options
        }));
        break;

      case 'section_chunk':
        handleSectionChunk(event.event_data);
        break;

      case 'process_completed':
        setState(prev => ({
          ...prev,
          currentStep: 'completed',
          finalArticle: {
            title: event.event_data.title,
            content: event.event_data.final_content,
            article_id: event.event_data.article_id
          },
          steps: prev.steps.map(step => ({ ...step, status: 'completed' }))
        }));
        break;

      case 'process_error':
        setState(prev => ({
          ...prev,
          error: {
            message: event.event_data.message,
            step: event.event_data.step,
            recoverable: event.event_data.error_type === 'recoverable'
          }
        }));
        break;

      default:
        console.log(`ğŸ¤· Unhandled event type: ${event.event_type}`);
    }
  }, []);

  // Process state update handler
  const handleProcessStateUpdate = useCallback((state: ProcessState) => {
    console.log(`ğŸ”„ Process state updated: ${state.current_step}`);
    
    setState(prev => ({
      ...prev,
      currentStep: state.current_step as GenerationStep,
      isWaitingForInput: state.is_waiting_for_input || false,
      inputType: state.expected_user_input as any
    }));
  }, []);

  // Supabase Realtime connection
  const realtimeConnection = useSupabaseRealtime({
    processId,
    userId,
    onProcessEvent: handleProcessEvent,
    onProcessStateUpdate: handleProcessStateUpdate,
    autoConnect
  });

  // Action functions
  const selectPersona = useCallback(async (selectedId: number) => {
    if (!processId) return;
    
    try {
      const response = await fetch(`/api/articles/generation/${processId}/user-input`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          response_type: 'SELECT_PERSONA',
          payload: { selected_id: selectedId }
        })
      });
      
      if (!response.ok) throw new Error('Failed to submit persona selection');
      
      setState(prev => ({
        ...prev,
        isWaitingForInput: false,
        inputType: undefined
      }));
      
    } catch (error) {
      console.error('âŒ Failed to select persona:', error);
    }
  }, [processId]);

  const selectTheme = useCallback(async (selectedIndex: number) => {
    if (!processId) return;
    
    try {
      const response = await fetch(`/api/articles/generation/${processId}/user-input`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          response_type: 'SELECT_THEME',
          payload: { selected_index: selectedIndex }
        })
      });
      
      if (!response.ok) throw new Error('Failed to submit theme selection');
      
      setState(prev => ({
        ...prev,
        isWaitingForInput: false,
        inputType: undefined
      }));
      
    } catch (error) {
      console.error('âŒ Failed to select theme:', error);
    }
  }, [processId]);

  return {
    // State
    state,
    
    // Connection status
    isConnected: realtimeConnection.isConnected,
    isConnecting: realtimeConnection.isConnecting,
    connectionError: realtimeConnection.connectionError,
    
    // Actions
    selectPersona,
    selectTheme,
    
    // Connection control
    connect: realtimeConnection.connect,
    disconnect: realtimeConnection.disconnect
  };
};
```

## ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨å¾©æ—§æ©Ÿèƒ½

### æ¥ç¶šã‚¨ãƒ©ãƒ¼ã®å‡¦ç†

```typescript
interface ConnectionRecoveryManager {
  maxRetries: number;
  retryInterval: number;
  backoffMultiplier: number;
  
  async recoverConnection(processId: string): Promise<boolean>;
  async syncMissedEvents(processId: string, lastEventSequence: number): Promise<ProcessEvent[]>;
}

class RealtimeConnectionRecovery implements ConnectionRecoveryManager {
  maxRetries = 5;
  retryInterval = 1000; // 1 second
  backoffMultiplier = 2;
  
  async recoverConnection(processId: string): Promise<boolean> {
    let attempts = 0;
    let delay = this.retryInterval;
    
    while (attempts < this.maxRetries) {
      try {
        // Try to reconnect
        const connection = await this.establishConnection(processId);
        if (connection.isConnected) {
          console.log(`âœ… Connection recovered after ${attempts + 1} attempts`);
          return true;
        }
      } catch (error) {
        console.warn(`ğŸ”„ Retry attempt ${attempts + 1} failed:`, error);
      }
      
      attempts++;
      await new Promise(resolve => setTimeout(resolve, delay));
      delay *= this.backoffMultiplier;
    }
    
    console.error(`âŒ Failed to recover connection after ${this.maxRetries} attempts`);
    return false;
  }
  
  async syncMissedEvents(processId: string, lastEventSequence: number): Promise<ProcessEvent[]> {
    try {
      const response = await fetch(`/api/articles/generation/${processId}/events?since_sequence=${lastEventSequence}`);
      if (!response.ok) throw new Error('Failed to fetch missed events');
      
      const missedEvents = await response.json();
      console.log(`ğŸ“¥ Synced ${missedEvents.length} missed events`);
      return missedEvents;
    } catch (error) {
      console.error('âŒ Failed to sync missed events:', error);
      return [];
    }
  }
  
  private async establishConnection(processId: string): Promise<{ isConnected: boolean }> {
    // Implementation of connection establishment
    return { isConnected: true };
  }
}
```

### ãƒ‡ãƒã‚¦ãƒ³ã‚¹æ©Ÿèƒ½ã«ã‚ˆã‚‹é…ä¿¡æœ€é©åŒ–

```python
class RealtimeEventDebouncer:
    """ã‚¤ãƒ™ãƒ³ãƒˆé…ä¿¡ã®é »åº¦åˆ¶å¾¡ã¨ãƒ‡ãƒã‚¦ãƒ³ã‚¹å‡¦ç†"""
    
    def __init__(self, min_interval: float = 0.2):
        self.min_interval = min_interval
        self.last_event_times: Dict[str, float] = {}
        self.pending_events: Dict[str, Dict] = {}
        self.debounce_tasks: Dict[str, asyncio.Task] = {}
    
    async def debounced_publish(
        self, 
        process_id: str, 
        event_type: str, 
        event_data: Dict[str, Any],
        force_immediate: bool = False
    ):
        """ãƒ‡ãƒã‚¦ãƒ³ã‚¹å‡¦ç†ä»˜ãã‚¤ãƒ™ãƒ³ãƒˆé…ä¿¡"""
        
        event_key = f"{process_id}:{event_type}"
        current_time = time.time()
        
        # å¼·åˆ¶å³åº§é…ä¿¡ã¾ãŸã¯æœ€å°é–“éš”çµŒéã®å ´åˆã¯å³åº§ã«é…ä¿¡
        if force_immediate or self._should_publish_immediately(event_key, current_time):
            await self._publish_immediately(process_id, event_type, event_data)
            return
        
        # ãƒ‡ãƒã‚¦ãƒ³ã‚¹å‡¦ç†ï¼šå¾Œç¶šã‚¤ãƒ™ãƒ³ãƒˆã§ä¸Šæ›¸ã
        self.pending_events[event_key] = {
            "process_id": process_id,
            "event_type": event_type,
            "event_data": event_data
        }
        
        # æ—¢å­˜ã®ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¦æ–°ã—ã„ã‚¿ã‚¹ã‚¯ã‚’ä½œæˆ
        if event_key in self.debounce_tasks:
            self.debounce_tasks[event_key].cancel()
        
        delay = self.min_interval - (current_time - self.last_event_times.get(event_key, 0))
        self.debounce_tasks[event_key] = asyncio.create_task(
            self._delayed_publish(event_key, max(0, delay))
        )
    
    def _should_publish_immediately(self, event_key: str, current_time: float) -> bool:
        """å³åº§é…ä¿¡ã®åˆ¤å®š"""
        last_time = self.last_event_times.get(event_key, 0)
        return (current_time - last_time) >= self.min_interval
    
    async def _delayed_publish(self, event_key: str, delay: float):
        """é…å»¶é…ä¿¡ã®å®Ÿè¡Œ"""
        try:
            await asyncio.sleep(delay)
            
            if event_key in self.pending_events:
                event_info = self.pending_events.pop(event_key)
                await self._publish_immediately(
                    event_info["process_id"],
                    event_info["event_type"],
                    event_info["event_data"]
                )
                
        except asyncio.CancelledError:
            # ã‚¿ã‚¹ã‚¯ãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚ŒãŸå ´åˆã¯ä½•ã‚‚ã—ãªã„
            pass
        finally:
            # ã‚¿ã‚¹ã‚¯ã‚’è¾æ›¸ã‹ã‚‰å‰Šé™¤
            self.debounce_tasks.pop(event_key, None)
    
    async def _publish_immediately(self, process_id: str, event_type: str, event_data: Dict[str, Any]):
        """å³åº§é…ä¿¡ã®å®Ÿè¡Œ"""
        event_key = f"{process_id}:{event_type}"
        
        await self.event_publisher.publish_event(
            process_id=process_id,
            event_type=event_type,
            event_data=event_data
        )
        
        self.last_event_times[event_key] = time.time()
```

## ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è€ƒæ…®äº‹é …

### ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æœ€é©åŒ–

#### ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ‹ãƒ³ã‚°æˆ¦ç•¥
```sql
-- process_events ãƒ†ãƒ¼ãƒ–ãƒ«ã®æœˆæ¬¡ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³
CREATE TABLE process_events (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    process_id UUID NOT NULL,
    event_type TEXT NOT NULL,
    event_data JSONB NOT NULL DEFAULT '{}'::jsonb,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    -- ãã®ä»–ã®ã‚«ãƒ©ãƒ 
) PARTITION BY RANGE (created_at);

-- æœˆæ¬¡ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ã®ä½œæˆ
CREATE TABLE process_events_2025_01 PARTITION OF process_events
    FOR VALUES FROM ('2025-01-01') TO ('2025-02-01');

CREATE TABLE process_events_2025_02 PARTITION OF process_events
    FOR VALUES FROM ('2025-02-01') TO ('2025-03-01');
```

#### è‡ªå‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
```sql
-- å¤ã„ã‚¤ãƒ™ãƒ³ãƒˆã®è‡ªå‹•å‰Šé™¤ï¼ˆ3ãƒ¶æœˆçµŒéå¾Œï¼‰
CREATE OR REPLACE FUNCTION cleanup_old_process_events()
RETURNS void AS $$
BEGIN
    DELETE FROM process_events 
    WHERE created_at < NOW() - INTERVAL '3 months'
      AND archived = false;
    
    -- ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒ•ãƒ©ã‚°ã‚’ã‚»ãƒƒãƒˆï¼ˆé‡è¦ãªã‚¤ãƒ™ãƒ³ãƒˆã¯ä¿æŒï¼‰
    UPDATE process_events 
    SET archived = true 
    WHERE created_at < NOW() - INTERVAL '1 month'
      AND event_category IN ('system', 'debug');
END;
$$ LANGUAGE plpgsql;

-- æ—¥æ¬¡å®Ÿè¡Œã®cronã‚¸ãƒ§ãƒ–è¨­å®š
SELECT cron.schedule('cleanup-process-events', '0 2 * * *', 'SELECT cleanup_old_process_events();');
```

### ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰æœ€é©åŒ–

#### ã‚¤ãƒ™ãƒ³ãƒˆå‡¦ç†ã®æœ€é©åŒ–
```typescript
// ãƒ¡ãƒ¢åŒ–ã«ã‚ˆã‚‹å†ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°æŠ‘åˆ¶
const ProcessEventHandler = memo(({ event }: { event: ProcessEvent }) => {
  const processEvent = useCallback((event: ProcessEvent) => {
    // Heavy processing
  }, []);

  useEffect(() => {
    processEvent(event);
  }, [event.id, processEvent]); // IDãƒ™ãƒ¼ã‚¹ã®ä¾å­˜é–¢ä¿‚

  return null;
});

// ãƒãƒƒãƒå‡¦ç†ã«ã‚ˆã‚‹çŠ¶æ…‹æ›´æ–°
const useBatchedStateUpdates = () => {
  const [pendingUpdates, setPendingUpdates] = useState<StateUpdate[]>([]);
  
  useEffect(() => {
    if (pendingUpdates.length === 0) return;
    
    const timeoutId = setTimeout(() => {
      // ãƒãƒƒãƒã§çŠ¶æ…‹æ›´æ–°ã‚’å®Ÿè¡Œ
      const batchedUpdate = pendingUpdates.reduce(combineUpdates, {});
      applyStateUpdate(batchedUpdate);
      setPendingUpdates([]);
    }, 50); // 50ms ã®ãƒ‡ãƒã‚¦ãƒ³ã‚¹
    
    return () => clearTimeout(timeoutId);
  }, [pendingUpdates]);
  
  return useCallback((update: StateUpdate) => {
    setPendingUpdates(prev => [...prev, update]);
  }, []);
};
```

## ç›£è¦–ã¨ãƒ‡ãƒãƒƒã‚°

### ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€šä¿¡ã®ç›£è¦–

#### ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
```python
class RealtimeMetricsCollector:
    """Realtimeé€šä¿¡ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†"""
    
    def __init__(self):
        self.metrics = {
            "events_published": 0,
            "events_failed": 0,
            "active_connections": 0,
            "average_event_size": 0,
            "event_delivery_time": []
        }
    
    async def record_event_published(self, event_size: int, delivery_time: float):
        """ã‚¤ãƒ™ãƒ³ãƒˆé…ä¿¡ã®è¨˜éŒ²"""
        self.metrics["events_published"] += 1
        self.metrics["average_event_size"] = (
            (self.metrics["average_event_size"] * (self.metrics["events_published"] - 1) + event_size) 
            / self.metrics["events_published"]
        )
        self.metrics["event_delivery_time"].append(delivery_time)
        
        # ç›´è¿‘100ä»¶ã®ã¿ä¿æŒ
        if len(self.metrics["event_delivery_time"]) > 100:
            self.metrics["event_delivery_time"].pop(0)
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚µãƒãƒªãƒ¼ã®å–å¾—"""
        delivery_times = self.metrics["event_delivery_time"]
        
        return {
            "total_events": self.metrics["events_published"],
            "failed_events": self.metrics["events_failed"],
            "success_rate": (
                (self.metrics["events_published"] - self.metrics["events_failed"]) 
                / max(self.metrics["events_published"], 1) * 100
            ),
            "average_event_size_bytes": self.metrics["average_event_size"],
            "average_delivery_time_ms": sum(delivery_times) / len(delivery_times) if delivery_times else 0,
            "p95_delivery_time_ms": sorted(delivery_times)[int(len(delivery_times) * 0.95)] if delivery_times else 0
        }
```

#### ãƒ‡ãƒãƒƒã‚°ç”¨ãƒ„ãƒ¼ãƒ«
```typescript
// Realtime ã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒãƒƒã‚¬ãƒ¼
class RealtimeDebugger {
  private eventLog: ProcessEvent[] = [];
  private maxLogSize = 1000;
  
  logEvent(event: ProcessEvent) {
    this.eventLog.unshift({
      ...event,
      received_at: new Date().toISOString()
    });
    
    if (this.eventLog.length > this.maxLogSize) {
      this.eventLog.pop();
    }
    
    // ãƒ‡ãƒãƒƒã‚°ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›
    console.group(`ğŸ“¨ ${event.event_type} (seq: ${event.event_sequence})`);
    console.log('Process ID:', event.process_id);
    console.log('Category:', event.event_category);
    console.log('Data:', event.event_data);
    console.log('Timestamp:', event.created_at);
    console.groupEnd();
  }
  
  getEventHistory(processId?: string, eventType?: string): ProcessEvent[] {
    return this.eventLog.filter(event => 
      (!processId || event.process_id === processId) &&
      (!eventType || event.event_type === eventType)
    );
  }
  
  exportEventLog(): string {
    return JSON.stringify(this.eventLog, null, 2);
  }
  
  clearLog() {
    this.eventLog = [];
  }
}

// ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ‡ãƒãƒƒã‚¬ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ï¼ˆé–‹ç™ºç’°å¢ƒã®ã¿ï¼‰
export const realtimeDebugger = process.env.NODE_ENV === 'development' 
  ? new RealtimeDebugger() 
  : null;
```

ã“ã®Supabase Realtimeé€£æºä»•æ§˜ã«ã‚ˆã‚Šã€å¾“æ¥ã®WebSocketé€šä¿¡ã®å•é¡Œç‚¹ã‚’è§£æ±ºã—ã€ã‚ˆã‚Šä¿¡é ¼æ€§ãŒé«˜ãæ‹¡å¼µæ€§ã®ã‚ã‚‹ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€šä¿¡ã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿç¾ã—ã¦ã„ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å¤‰æ›´ã‚’ç›´æ¥ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é…ä¿¡ã«æ´»ç”¨ã™ã‚‹ã“ã¨ã§ã€ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ã‚’ä¿è¨¼ã—ãªãŒã‚‰åŠ¹ç‡çš„ãªéåŒæœŸå‡¦ç†ã‚’æä¾›ã—ã¾ã™ã€‚